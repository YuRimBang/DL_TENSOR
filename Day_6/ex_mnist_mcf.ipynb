{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중분류 모델\n",
    "- 손실 함수\n",
    "- 성능평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initializing libiomp5md.dll, but found libiomp5md.dll already initialized\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 로딩 -> 내장 데이터셋 load_data()\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (60000, 28, 28), y_train : (60000,)\n",
      "X_test : (10000, 28, 28), y_test : (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train : {X_train.shape}, y_train : {y_train.shape}')\n",
    "print(f'X_test : {X_test.shape}, y_test : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])\n",
    "plt.title(f'[LABEL {y_train[0]}]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [2] 데이터 전처리 <hr>\n",
    "    * 피쳐 : 타입, 정규화, 1D\n",
    "    * 타겟 : 인코딩 -> One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_max : 1.0 , x_train_min : 0.0, x_train_shape : (60000, 28, 28), x_train_dtype : float64\n",
      "x_test_max : 1.0 , x_test_min : 0.0, x_test_shape : (10000, 28, 28), x_test_dtype : float64\n"
     ]
    }
   ],
   "source": [
    "## 피쳐 -> 타입, 정규화 (0.0 ~ 1.0), 2D -> 1D\n",
    "## [1] ) ~ 255 -> 0.0 ~ 1.0\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "print(f'x_train_max : {X_train.max()} , x_train_min : {X_train.min()}, x_train_shape : {X_train.shape}, x_train_dtype : {X_train.dtype}')\n",
    "print(f'x_test_max : {X_test.max()} , x_test_min : {X_test.min()}, x_test_shape : {X_test.shape}, x_test_dtype : {X_test.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [2] float64 -> float 32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : 0.0, 1.0 (60000, 784), float32\n",
      "X_test  : 0.0, 1.0 (10000, 784), float32\n"
     ]
    }
   ],
   "source": [
    "## [3] 2D (28, 28) ==> 1D (28*28)\n",
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test  = X_test.reshape(-1, 28*28)\n",
    "\n",
    "print(f'X_train : {X_train.min()}, {X_train.max()} {X_train.shape}, {X_train.dtype}')\n",
    "print(f'X_test  : {X_test.min()}, {X_test.max()} {X_test.shape}, {X_test.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## 라벨 ->  One-Hot Encoding\n",
    "y_train = tf.one_hot(y_train, depth=10)\n",
    "y_test = tf.one_hot(y_test, depth=10)\n",
    "\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 모델 클래스 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------------------------------------------------------------------\n",
    "## 클래스이름 : MNISTModel\n",
    "## ----------------------------------------------------------------------------------\n",
    "## 입력층 : 입력/피쳐개수     784     출력/뉴런개수 300      활성화함수  ReLu\n",
    "## 은닉층 : 입력/이전층뉴런수 300     출력/뉴런개수 100      활성화함수  ReLu\n",
    "## 출력층 : 입력/이전층뉴런수 100     출력/라벨개수 10       활성화함수  회귀/이진/다중\n",
    "## ----------------------------------------------------------------------------------\n",
    "#class MNISTModel(tf.Module):\n",
    "class MNISTModel():\n",
    "    # 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        #super().__init__()\n",
    "        # 입력층\n",
    "        self.in_w=tf.Variable(tf.random.normal([784,300]))\n",
    "        self.in_b=tf.Variable(tf.random.normal([300]))\n",
    "\n",
    "        # 은닉층\n",
    "        self.hd_w=tf.Variable(tf.random.normal([300,100]))\n",
    "        self.hd_b=tf.Variable(tf.random.normal([100]))\n",
    "\n",
    "        # 출력층\n",
    "        self.out_w=tf.Variable(tf.random.normal([100,10]))\n",
    "        self.out_b=tf.Variable(tf.random.normal([10]))\n",
    "\n",
    "    # 순방향 학습 메서드\n",
    "    def __call__(self, data):\n",
    "        # 입력층\n",
    "        wbs=tf.matmul(data, self.in_w) + self.in_b\n",
    "        output=tf.nn.relu(wbs)\n",
    "\n",
    "        # 은닉층\n",
    "        wbs=tf.matmul(output, self.hd_w) + self.hd_b\n",
    "        output=tf.nn.relu(wbs)\n",
    "\n",
    "        # 출력층 ==> Tensorflow에서 출력층의 가중합+절편 값 => 로짓(logits)\n",
    "        logits=tf.matmul(output, self.out_w) + self.out_b\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습관련 설정 <hr>\n",
    "* 학습 횟수 즉, 에포크 개수\n",
    "* 학습 데이터량 즉, 배치 사이즈\n",
    "* 1에포크에 학습 횟수, 즉, 배치 개수\n",
    "* 최적화 즉, 가중치와 절편 업데이트 간격으로 러닝레이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 학습 관련 설정\n",
    "LR= 0.001               # 일반적 0.0001 ~ 0.1\n",
    "EPOCHS = 50             # 학습 데이터를 처음부터 끝까지는 몇 번 학습할지 횟수 설정\n",
    "BATCH_SIZE = 600        # 한번에 학습할 데이터 양\n",
    "DATA_NUMS = 60000       # 전체 학습용 데이터 개수\n",
    "FEATURES = 784          # 피쳐 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 데이터셋 인스턴스 생성 ==> 지도학습 : 피쳐+라벨\n",
    "TRAIN_DS = Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "#### 배치크기만큼 데이터 추출하는 데이터셋 인스턴스 생성\n",
    "TRAIN_DS = TRAIN_DS.shuffle(DATA_NUMS).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 784) (600, 10)\n",
      "tf.Tensor(\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00784314 0.40784314 0.9764706  0.99607843\n",
      " 1.         0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.07843138\n",
      " 0.7294118  0.99215686 0.99215686 0.99215686 0.9098039  0.08627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01568628 0.6862745  0.99215686 0.99215686\n",
      " 0.93333334 0.38039216 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.20392157 0.99215686 0.99215686 0.8352941  0.10588235 0.\n",
      " 0.         0.01176471 0.26666668 0.4509804  0.5529412  0.15686275\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.63529414 0.99215686\n",
      " 0.99215686 0.15686275 0.         0.         0.         0.38039216\n",
      " 0.99215686 0.99215686 0.9647059  0.46666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.5294118  0.99215686 0.99215686 0.09411765\n",
      " 0.         0.         0.25882354 0.94509804 0.99215686 0.8627451\n",
      " 0.29803923 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4117647  0.99215686 0.99215686 0.09411765 0.         0.\n",
      " 0.9529412  0.99215686 0.9372549  0.14117648 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.8980392\n",
      " 0.99215686 0.63529414 0.01960784 0.76862746 0.99607843 0.99215686\n",
      " 0.7058824  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.42745098 0.81960785 0.99215686\n",
      " 0.83137256 0.9882353  0.99607843 0.9529412  0.11764706 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.92941177 0.99215686 0.99215686\n",
      " 0.99607843 0.8235294  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.25882354 0.99607843 0.99607843 1.         0.99607843\n",
      " 0.827451   0.10196079 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.25882354\n",
      " 0.99215686 0.99215686 0.972549   0.9529412  0.99215686 0.9529412\n",
      " 0.3882353  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.25882354 0.99215686 0.99215686\n",
      " 0.6392157  0.14901961 0.99215686 0.99215686 0.8980392  0.06666667\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.3019608  0.99215686 0.99215686 0.43529412 0.01568628\n",
      " 0.79607844 0.99215686 0.99215686 0.40784314 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.8352941\n",
      " 0.99215686 0.99215686 0.6392157  0.         0.7372549  0.99215686\n",
      " 0.99215686 0.6862745  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.41568628 0.98039216 0.99215686\n",
      " 0.7019608  0.02352941 0.81960785 0.99215686 0.99215686 0.48235294\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.92941177 0.99215686 0.9607843  0.03921569\n",
      " 0.8784314  0.99215686 0.99215686 0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.84705883 0.99215686 0.99215686 0.69803923 0.99215686 0.99215686\n",
      " 0.84705883 0.01568628 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.13333334 0.7882353\n",
      " 0.99607843 0.99215686 0.99215686 0.9529412  0.4862745  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.01176471 0.5803922  0.99215686\n",
      " 0.99215686 0.54901963 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ], shape=(784,), dtype=float32) tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 1. 0.], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for data, label in TRAIN_DS:\n",
    "    print(data.shape, label.shape)\n",
    "    print(data[0], label[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 관련 함수들 <hr>\n",
    "* 손실함수\n",
    "* 성능평가 함수\n",
    "* 학습함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [1] 손실함수\n",
    "@tf.function\n",
    "def mcfLossFunc(y, logits):\n",
    "    return tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [2] 최적화 함수  => 모델의 층별로 존재하는 W, b를 업데이트 시켜주는 인스턴스\n",
    "## - 최적화인스턴스 생성\n",
    "## - 학습과정에서 새롭게 계산된 층별 W, b 값을 모델에 적용\n",
    "optimizer = tf.keras.optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [3] 학습관련 함수 => 모델 학습 + 손실 계산 + W,b 업데이트\n",
    "@tf.function\n",
    "def train(model, x, y):\n",
    "    # 전방향 학습 기록\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 학습 진행\n",
    "        y_pred = model(x)\n",
    "        # 손실 계산\n",
    "        loss = mcfLossFunc(y, y_pred)\n",
    "\n",
    "    # 손실에 대한 새로운 W, b 계산\n",
    "    new_gradients=tape.gradient(loss, vars(model).values())\n",
    "\n",
    "    # 새로운 W,b 업데이트 단, 새로운 가중치 값과 변수 쌍으로 묶어서 전달\n",
    "    optimizer.apply_gradients( zip( new_gradients, vars(model).values() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['in_w', 'in_b', 'hd_w', 'hd_b', 'out_w', 'out_b'])\n"
     ]
    }
   ],
   "source": [
    "#### [ 테스트 ]\n",
    "m=MNISTModel()\n",
    "\n",
    "# 인스턴스의 지역변수 키와 값 읽기 Dict 형태\n",
    "m_vars=vars(m)\n",
    "\n",
    "print(m_vars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [4] 정확도 계산 함수 ==> accuracy\n",
    "@tf.function\n",
    "def accuracy(y_pred, y):\n",
    "\n",
    "    correct = tf.equal( tf.argmax(y_pred, axis=1),  tf.argmax(y, axis=1))\n",
    "\n",
    "    return tf.reduce_mean( tf.cast(correct, tf.float32) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 인스턴스\n",
    "MyModel=MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[에포크 - 0/50] 평균 Loss : 291.2976379394531, 정확도 : 0.6847000122070312\n",
      "[에포크 - 1/50] 평균 Loss : 73.8895492553711, 정확도 : 0.8026000261306763\n",
      "[에포크 - 2/50] 평균 Loss : 47.171234130859375, 정확도 : 0.8438000082969666\n",
      "[에포크 - 3/50] 평균 Loss : 35.545230865478516, 정확도 : 0.8654000163078308\n",
      "[에포크 - 4/50] 평균 Loss : 28.67670249938965, 정확도 : 0.8776999711990356\n",
      "[에포크 - 5/50] 평균 Loss : 23.988405227661133, 정확도 : 0.8865000009536743\n",
      "[에포크 - 6/50] 평균 Loss : 20.582014083862305, 정확도 : 0.8946999907493591\n",
      "[에포크 - 7/50] 평균 Loss : 18.024188995361328, 정확도 : 0.899399995803833\n",
      "[에포크 - 8/50] 평균 Loss : 15.9015531539917, 정확도 : 0.902899980545044\n",
      "[에포크 - 9/50] 평균 Loss : 14.155799865722656, 정확도 : 0.9082000255584717\n",
      "[에포크 - 10/50] 평균 Loss : 12.592058181762695, 정확도 : 0.9125999808311462\n",
      "[에포크 - 11/50] 평균 Loss : 11.276815414428711, 정확도 : 0.9142000079154968\n",
      "[에포크 - 12/50] 평균 Loss : 10.167778015136719, 정확도 : 0.9154000282287598\n",
      "[에포크 - 13/50] 평균 Loss : 9.115449905395508, 정확도 : 0.9182000160217285\n",
      "[에포크 - 14/50] 평균 Loss : 8.259273529052734, 정확도 : 0.9204000234603882\n",
      "[에포크 - 15/50] 평균 Loss : 7.409143447875977, 정확도 : 0.9225999712944031\n",
      "[에포크 - 16/50] 평균 Loss : 6.734584808349609, 정확도 : 0.9236999750137329\n",
      "[에포크 - 17/50] 평균 Loss : 6.091195106506348, 정확도 : 0.9247000217437744\n",
      "[에포크 - 18/50] 평균 Loss : 5.5414557456970215, 정확도 : 0.9254999756813049\n",
      "[에포크 - 19/50] 평균 Loss : 5.036093235015869, 정확도 : 0.9273999929428101\n",
      "[에포크 - 20/50] 평균 Loss : 4.558150291442871, 정확도 : 0.9283000230789185\n",
      "[에포크 - 21/50] 평균 Loss : 4.1387410163879395, 정확도 : 0.9289000034332275\n",
      "[에포크 - 22/50] 평균 Loss : 3.7398226261138916, 정확도 : 0.9297000169754028\n",
      "[에포크 - 23/50] 평균 Loss : 3.416013717651367, 정확도 : 0.9309999942779541\n",
      "[에포크 - 24/50] 평균 Loss : 3.0622100830078125, 정확도 : 0.9318000078201294\n",
      "[에포크 - 25/50] 평균 Loss : 2.789161443710327, 정확도 : 0.932699978351593\n",
      "[에포크 - 26/50] 평균 Loss : 2.5291755199432373, 정확도 : 0.9333000183105469\n",
      "[에포크 - 27/50] 평균 Loss : 2.2786576747894287, 정확도 : 0.9333000183105469\n",
      "[에포크 - 28/50] 평균 Loss : 2.022263765335083, 정확도 : 0.9327999949455261\n",
      "[에포크 - 29/50] 평균 Loss : 1.8158149719238281, 정확도 : 0.9314000010490417\n",
      "[에포크 - 30/50] 평균 Loss : 1.6229820251464844, 정확도 : 0.9351999759674072\n",
      "[에포크 - 31/50] 평균 Loss : 1.4597101211547852, 정확도 : 0.933899998664856\n",
      "[에포크 - 32/50] 평균 Loss : 1.298028588294983, 정확도 : 0.9358000159263611\n",
      "[에포크 - 33/50] 평균 Loss : 1.167799949645996, 정확도 : 0.9366000294685364\n",
      "[에포크 - 34/50] 평균 Loss : 1.0329716205596924, 정확도 : 0.9363999962806702\n",
      "[에포크 - 35/50] 평균 Loss : 0.9111301302909851, 정확도 : 0.9369000196456909\n",
      "[에포크 - 36/50] 평균 Loss : 0.8142838478088379, 정확도 : 0.9387000203132629\n",
      "[에포크 - 37/50] 평균 Loss : 0.7222772240638733, 정확도 : 0.9373000264167786\n",
      "[에포크 - 38/50] 평균 Loss : 0.6302579641342163, 정확도 : 0.9365000128746033\n",
      "[에포크 - 39/50] 평균 Loss : 0.5592281818389893, 정확도 : 0.9370999932289124\n",
      "[에포크 - 40/50] 평균 Loss : 0.4740222692489624, 정확도 : 0.935699999332428\n",
      "[에포크 - 41/50] 평균 Loss : 0.41752758622169495, 정확도 : 0.9359999895095825\n",
      "[에포크 - 42/50] 평균 Loss : 0.353372186422348, 정확도 : 0.9383999705314636\n",
      "[에포크 - 43/50] 평균 Loss : 0.3009057939052582, 정확도 : 0.9376000165939331\n",
      "[에포크 - 44/50] 평균 Loss : 0.2550073564052582, 정확도 : 0.9366999864578247\n",
      "[에포크 - 45/50] 평균 Loss : 0.2201017439365387, 정확도 : 0.9380000233650208\n",
      "[에포크 - 46/50] 평균 Loss : 0.19070610404014587, 정확도 : 0.9381999969482422\n",
      "[에포크 - 47/50] 평균 Loss : 0.15521015226840973, 정확도 : 0.9376999735832214\n",
      "[에포크 - 48/50] 평균 Loss : 0.1349836140871048, 정확도 : 0.9386000037193298\n",
      "[에포크 - 49/50] 평균 Loss : 0.10427390038967133, 정확도 : 0.9388999938964844\n"
     ]
    }
   ],
   "source": [
    "LOSS_HISTORY, ACC_HISTORY=[], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    total_loss =0\n",
    "\n",
    "    # 배치크기만큼 학습\n",
    "    for batch_x, batch_y in TRAIN_DS:\n",
    "\n",
    "        # 학습 및 가중치, 절편 업데이트\n",
    "        train(MyModel, batch_x, batch_y)\n",
    "\n",
    "        # 가중치, 절편 업데이트된 값으로 Loss 계산\n",
    "        current_loss = mcfLossFunc(batch_y, MyModel(batch_x))\n",
    "\n",
    "        # 1에포크에 대한 Loss 계산 위해서 누적\n",
    "        total_loss += current_loss\n",
    "\n",
    "    # 1에포크에 대한 평균 Loss\n",
    "    one_loss= total_loss/(DATA_NUMS//BATCH_SIZE)\n",
    "    LOSS_HISTORY.append(one_loss)\n",
    "\n",
    "    # 1에포크에 대한 정확도\n",
    "    one_acc=accuracy(MyModel(X_test), y_test)\n",
    "\n",
    "    print(f'[에포크 - {epoch}/{EPOCHS}] 평균 Loss : {one_loss}, 정확도 : {one_acc}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7] 테스트 이미지 <hr>\n",
    "- 이미지 처리 관련 패키지 설치\n",
    "    * %pip install opencv-python\n",
    "    * %pip install pillow  ===> [확인] from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in f:\\anaconda\\envs\\tensor_39\\lib\\site-packages (10.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open('my_two.jpg').convert('L')\n",
    "img=img.resize((28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (28, 28))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array=np.array(img)\n",
    "type(img_array), img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 212, 143, 111, 148,\n",
       "        237, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 244, 108,  83, 147, 186, 134,\n",
       "         64, 180, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 122, 127, 253, 255, 255, 255,\n",
       "        218,  65, 209, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 101, 206, 255, 255, 255, 255,\n",
       "        255, 192,  85, 252, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 240, 246, 255, 255, 255, 255,\n",
       "        255, 255,  84, 219, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 133, 161, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 172, 128, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 166, 130, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 106, 181, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 217,  72, 241, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        244,  80, 180, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254,\n",
       "         99, 140, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 246, 102,\n",
       "        112, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 227,  78, 137,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 254, 164,  65, 170, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 233, 171,  93, 105, 232, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 186,  41,   5,  67, 125, 125, 121, 121,\n",
       "        121, 121, 121, 121, 121, 121, 121,  99, 108, 252, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 242, 223, 215, 189, 181, 181, 181, 181,\n",
       "        181, 181, 181, 181, 181, 181, 181, 189, 223, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TENSOR_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
